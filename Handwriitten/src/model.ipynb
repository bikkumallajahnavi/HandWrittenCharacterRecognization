{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1e6a204c6780>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataloader_iam\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataloader_iam import Batch\n",
    "\n",
    "# Disable eager mode\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "class DecoderType:\n",
    "    \"\"\"CTC decoder types.\"\"\"\n",
    "    BestPath = 0\n",
    "    BeamSearch = 1\n",
    "    WordBeamSearch = 2\n",
    "\n",
    "\n",
    "class Model:\n",
    "    \"\"\"Minimalistic TF model for HTR.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 char_list: List[str],\n",
    "                 decoder_type: str = DecoderType.BestPath,\n",
    "                 must_restore: bool = False,\n",
    "                 dump: bool = False) -> None:\n",
    "        \"\"\"Init model: add CNN, RNN and CTC and initialize TF.\"\"\"\n",
    "        self.dump = dump\n",
    "        self.char_list = char_list\n",
    "        self.decoder_type = decoder_type\n",
    "        self.must_restore = must_restore\n",
    "        self.snap_ID = 0\n",
    "\n",
    "        # Whether to use normalization over a batch or a population\n",
    "        self.is_train = tf.compat.v1.placeholder(tf.bool, name='is_train')\n",
    "\n",
    "        # input image batch\n",
    "        self.input_imgs = tf.compat.v1.placeholder(tf.float32, shape=(None, None, None))\n",
    "\n",
    "        # setup CNN, RNN and CTC\n",
    "        self.setup_cnn()\n",
    "        self.setup_rnn()\n",
    "        self.setup_ctc()\n",
    "\n",
    "        # setup optimizer to train NN\n",
    "        self.batches_trained = 0\n",
    "        self.update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(self.update_ops):\n",
    "            self.optimizer = tf.compat.v1.train.AdamOptimizer().minimize(self.loss)\n",
    "\n",
    "        # initialize TF\n",
    "        self.sess, self.saver = self.setup_tf()\n",
    "\n",
    "    def setup_cnn(self) -> None:\n",
    "        \"\"\"Create CNN layers.\"\"\"\n",
    "        cnn_in4d = tf.expand_dims(input=self.input_imgs, axis=3)\n",
    "\n",
    "        # list of parameters for the layers\n",
    "        kernel_vals = [5, 5, 3, 3, 3]\n",
    "        feature_vals = [1, 32, 64, 128, 128, 256]\n",
    "        stride_vals = pool_vals = [(2, 2), (2, 2), (1, 2), (1, 2), (1, 2)]\n",
    "        num_layers = len(stride_vals)\n",
    "\n",
    "        # create layers\n",
    "        pool = cnn_in4d  # input to first CNN layer\n",
    "        for i in range(num_layers):\n",
    "            kernel = tf.Variable(\n",
    "                tf.random.truncated_normal([kernel_vals[i], kernel_vals[i], feature_vals[i], feature_vals[i + 1]],\n",
    "                                           stddev=0.1))\n",
    "            conv = tf.nn.conv2d(input=pool, filters=kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            conv_norm = tf.compat.v1.layers.batch_normalization(conv, training=self.is_train)\n",
    "            relu = tf.nn.relu(conv_norm)\n",
    "            pool = tf.nn.max_pool2d(input=relu, ksize=(1, pool_vals[i][0], pool_vals[i][1], 1),\n",
    "                                    strides=(1, stride_vals[i][0], stride_vals[i][1], 1), padding='VALID')\n",
    "\n",
    "        self.cnn_out_4d = pool\n",
    "\n",
    "    def setup_rnn(self) -> None:\n",
    "        \"\"\"Create RNN layers.\"\"\"\n",
    "        rnn_in3d = tf.squeeze(self.cnn_out_4d, axis=[2])\n",
    "\n",
    "        # basic cells which is used to build RNN\n",
    "        num_hidden = 256\n",
    "        cells = [tf.compat.v1.nn.rnn_cell.LSTMCell(num_units=num_hidden, state_is_tuple=True) for _ in\n",
    "                 range(2)]  # 2 layers\n",
    "\n",
    "        # stack basic cells\n",
    "        stacked = tf.compat.v1.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "        # bidirectional RNN\n",
    "        # BxTxF -> BxTx2H\n",
    "        (fw, bw), _ = tf.compat.v1.nn.bidirectional_dynamic_rnn(cell_fw=stacked, cell_bw=stacked, inputs=rnn_in3d,\n",
    "                                                                dtype=rnn_in3d.dtype)\n",
    "\n",
    "        # BxTxH + BxTxH -> BxTx2H -> BxTx1X2H\n",
    "        concat = tf.expand_dims(tf.concat([fw, bw], 2), 2)\n",
    "\n",
    "        # project output to chars (including blank): BxTx1x2H -> BxTx1xC -> BxTxC\n",
    "        kernel = tf.Variable(tf.random.truncated_normal([1, 1, num_hidden * 2, len(self.char_list) + 1], stddev=0.1))\n",
    "        self.rnn_out_3d = tf.squeeze(tf.nn.atrous_conv2d(value=concat, filters=kernel, rate=1, padding='SAME'),\n",
    "                                     axis=[2])\n",
    "\n",
    "    def setup_ctc(self) -> None:\n",
    "        \"\"\"Create CTC loss and decoder.\"\"\"\n",
    "        # BxTxC -> TxBxC\n",
    "        self.ctc_in_3d_tbc = tf.transpose(a=self.rnn_out_3d, perm=[1, 0, 2])\n",
    "        # ground truth text as sparse tensor\n",
    "        self.gt_texts = tf.SparseTensor(tf.compat.v1.placeholder(tf.int64, shape=[None, 2]),\n",
    "                                        tf.compat.v1.placeholder(tf.int32, [None]),\n",
    "                                        tf.compat.v1.placeholder(tf.int64, [2]))\n",
    "\n",
    "        # calc loss for batch\n",
    "        self.seq_len = tf.compat.v1.placeholder(tf.int32, [None])\n",
    "        self.loss = tf.reduce_mean(\n",
    "            input_tensor=tf.compat.v1.nn.ctc_loss(labels=self.gt_texts, inputs=self.ctc_in_3d_tbc,\n",
    "                                                  sequence_length=self.seq_len,\n",
    "                                                  ctc_merge_repeated=True))\n",
    "\n",
    "        # calc loss for each element to compute label probability\n",
    "        self.saved_ctc_input = tf.compat.v1.placeholder(tf.float32,\n",
    "                                                        shape=[None, None, len(self.char_list) + 1])\n",
    "        self.loss_per_element = tf.compat.v1.nn.ctc_loss(labels=self.gt_texts, inputs=self.saved_ctc_input,\n",
    "                                                         sequence_length=self.seq_len, ctc_merge_repeated=True)\n",
    "\n",
    "        # best path decoding or beam search decoding\n",
    "        if self.decoder_type == DecoderType.BestPath:\n",
    "            self.decoder = tf.nn.ctc_greedy_decoder(inputs=self.ctc_in_3d_tbc, sequence_length=self.seq_len)\n",
    "        elif self.decoder_type == DecoderType.BeamSearch:\n",
    "            self.decoder = tf.nn.ctc_beam_search_decoder(inputs=self.ctc_in_3d_tbc, sequence_length=self.seq_len,\n",
    "                                                         beam_width=50)\n",
    "        # word beam search decoding (see https://github.com/githubharald/CTCWordBeamSearch)\n",
    "        elif self.decoder_type == DecoderType.WordBeamSearch:\n",
    "            # prepare information about language (dictionary, characters in dataset, characters forming words)\n",
    "            chars = ''.join(self.char_list)\n",
    "            word_chars = open('../model/wordCharList.txt').read().splitlines()[0]\n",
    "            corpus = open('../data/corpus.txt').read()\n",
    "\n",
    "            # decode using the \"Words\" mode of word beam search\n",
    "            from word_beam_search import WordBeamSearch\n",
    "            self.decoder = WordBeamSearch(50, 'Words', 0.0, corpus.encode('utf8'), chars.encode('utf8'),\n",
    "                                          word_chars.encode('utf8'))\n",
    "\n",
    "            # the input to the decoder must have softmax already applied\n",
    "            self.wbs_input = tf.nn.softmax(self.ctc_in_3d_tbc, axis=2)\n",
    "\n",
    "    def setup_tf(self) -> Tuple[tf.compat.v1.Session, tf.compat.v1.train.Saver]:\n",
    "        \"\"\"Initialize TF.\"\"\"\n",
    "        print('Python: ' + sys.version)\n",
    "        print('Tensorflow: ' + tf.__version__)\n",
    "\n",
    "        sess = tf.compat.v1.Session()  # TF session\n",
    "\n",
    "        saver = tf.compat.v1.train.Saver(max_to_keep=1)  # saver saves model to file\n",
    "        model_dir = '../model/'\n",
    "        latest_snapshot = tf.train.latest_checkpoint(model_dir)  # is there a saved model?\n",
    "\n",
    "        # if model must be restored (for inference), there must be a snapshot\n",
    "        if self.must_restore and not latest_snapshot:\n",
    "            raise Exception('No saved model found in: ' + model_dir)\n",
    "\n",
    "        # load saved model if available\n",
    "        if latest_snapshot:\n",
    "            print('Init with stored values from ' + latest_snapshot)\n",
    "            saver.restore(sess, latest_snapshot)\n",
    "        else:\n",
    "            print('Init with new values')\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "        return sess, saver\n",
    "\n",
    "    def to_sparse(self, texts: List[str]) -> Tuple[List[List[int]], List[int], List[int]]:\n",
    "        \"\"\"Put ground truth texts into sparse tensor for ctc_loss.\"\"\"\n",
    "        indices = []\n",
    "        values = []\n",
    "        shape = [len(texts), 0]  # last entry must be max(labelList[i])\n",
    "\n",
    "        # go over all texts\n",
    "        for batchElement, text in enumerate(texts):\n",
    "            # convert to string of label (i.e. class-ids)\n",
    "            label_str = [self.char_list.index(c) for c in text]\n",
    "            # sparse tensor must have size of max. label-string\n",
    "            if len(label_str) > shape[1]:\n",
    "                shape[1] = len(label_str)\n",
    "            # put each label into sparse tensor\n",
    "            for i, label in enumerate(label_str):\n",
    "                indices.append([batchElement, i])\n",
    "                values.append(label)\n",
    "\n",
    "        return indices, values, shape\n",
    "\n",
    "    def decoder_output_to_text(self, ctc_output: tuple, batch_size: int) -> List[str]:\n",
    "        \"\"\"Extract texts from output of CTC decoder.\"\"\"\n",
    "\n",
    "        # word beam search: already contains label strings\n",
    "        if self.decoder_type == DecoderType.WordBeamSearch:\n",
    "            label_strs = ctc_output\n",
    "\n",
    "        # TF decoders: label strings are contained in sparse tensor\n",
    "        else:\n",
    "            # ctc returns tuple, first element is SparseTensor\n",
    "            decoded = ctc_output[0][0]\n",
    "\n",
    "            # contains string of labels for each batch element\n",
    "            label_strs = [[] for _ in range(batch_size)]\n",
    "\n",
    "            # go over all indices and save mapping: batch -> values\n",
    "            for (idx, idx2d) in enumerate(decoded.indices):\n",
    "                label = decoded.values[idx]\n",
    "                batch_element = idx2d[0]  # index according to [b,t]\n",
    "                label_strs[batch_element].append(label)\n",
    "\n",
    "        # map labels to chars for all batch elements\n",
    "        return [''.join([self.char_list[c] for c in labelStr]) for labelStr in label_strs]\n",
    "\n",
    "    def train_batch(self, batch: Batch) -> float:\n",
    "        \"\"\"Feed a batch into the NN to train it.\"\"\"\n",
    "        num_batch_elements = len(batch.imgs)\n",
    "        max_text_len = batch.imgs[0].shape[0] // 4\n",
    "        sparse = self.to_sparse(batch.gt_texts)\n",
    "        eval_list = [self.optimizer, self.loss]\n",
    "        feed_dict = {self.input_imgs: batch.imgs, self.gt_texts: sparse,\n",
    "                     self.seq_len: [max_text_len] * num_batch_elements, self.is_train: True}\n",
    "        _, loss_val = self.sess.run(eval_list, feed_dict)\n",
    "        self.batches_trained += 1\n",
    "        return loss_val\n",
    "\n",
    "    @staticmethod\n",
    "    def dump_nn_output(rnn_output: np.ndarray) -> None:\n",
    "        \"\"\"Dump the output of the NN to CSV file(s).\"\"\"\n",
    "        dump_dir = '../dump/'\n",
    "        if not os.path.isdir(dump_dir):\n",
    "            os.mkdir(dump_dir)\n",
    "\n",
    "        # iterate over all batch elements and create a CSV file for each one\n",
    "        max_t, max_b, max_c = rnn_output.shape\n",
    "        for b in range(max_b):\n",
    "            csv = ''\n",
    "            for t in range(max_t):\n",
    "                for c in range(max_c):\n",
    "                    csv += str(rnn_output[t, b, c]) + ';'\n",
    "                csv += '\\n'\n",
    "            fn = dump_dir + 'rnnOutput_' + str(b) + '.csv'\n",
    "            print('Write dump of NN to file: ' + fn)\n",
    "            with open(fn, 'w') as f:\n",
    "                f.write(csv)\n",
    "\n",
    "    def infer_batch(self, batch: Batch, calc_probability: bool = False, probability_of_gt: bool = False):\n",
    "        \"\"\"Feed a batch into the NN to recognize the texts.\"\"\"\n",
    "\n",
    "        # decode, optionally save RNN output\n",
    "        num_batch_elements = len(batch.imgs)\n",
    "\n",
    "        # put tensors to be evaluated into list\n",
    "        eval_list = []\n",
    "\n",
    "        if self.decoder_type == DecoderType.WordBeamSearch:\n",
    "            eval_list.append(self.wbs_input)\n",
    "        else:\n",
    "            eval_list.append(self.decoder)\n",
    "\n",
    "        if self.dump or calc_probability:\n",
    "            eval_list.append(self.ctc_in_3d_tbc)\n",
    "\n",
    "        # sequence length depends on input image size (model downsizes width by 4)\n",
    "        max_text_len = batch.imgs[0].shape[0] // 4\n",
    "\n",
    "        # dict containing all tensor fed into the model\n",
    "        feed_dict = {self.input_imgs: batch.imgs, self.seq_len: [max_text_len] * num_batch_elements,\n",
    "                     self.is_train: False}\n",
    "\n",
    "        # evaluate model\n",
    "        eval_res = self.sess.run(eval_list, feed_dict)\n",
    "\n",
    "        # TF decoders: decoding already done in TF graph\n",
    "        if self.decoder_type != DecoderType.WordBeamSearch:\n",
    "            decoded = eval_res[0]\n",
    "        # word beam search decoder: decoding is done in C++ function compute()\n",
    "        else:\n",
    "            decoded = self.decoder.compute(eval_res[0])\n",
    "\n",
    "        # map labels (numbers) to character string\n",
    "        texts = self.decoder_output_to_text(decoded, num_batch_elements)\n",
    "\n",
    "        # feed RNN output and recognized text into CTC loss to compute labeling probability\n",
    "        probs = None\n",
    "        if calc_probability:\n",
    "            sparse = self.to_sparse(batch.gt_texts) if probability_of_gt else self.to_sparse(texts)\n",
    "            ctc_input = eval_res[1]\n",
    "            eval_list = self.loss_per_element\n",
    "            feed_dict = {self.saved_ctc_input: ctc_input, self.gt_texts: sparse,\n",
    "                         self.seq_len: [max_text_len] * num_batch_elements, self.is_train: False}\n",
    "            loss_vals = self.sess.run(eval_list, feed_dict)\n",
    "            probs = np.exp(-loss_vals)\n",
    "\n",
    "        # dump the output of the NN to CSV file(s)\n",
    "        if self.dump:\n",
    "            self.dump_nn_output(eval_res[1])\n",
    "\n",
    "        return texts, probs\n",
    "\n",
    "    def save(self) -> None:\n",
    "        \"\"\"Save model to file.\"\"\"\n",
    "        self.snap_ID += 1\n",
    "        self.saver.save(self.sess, '../model/snapshot', global_step=self.snap_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
