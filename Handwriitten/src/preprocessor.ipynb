{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from dataloader_iam import Batch\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self,\n",
    "                 img_size: Tuple[int, int],\n",
    "                 padding: int = 0,\n",
    "                 dynamic_width: bool = False,\n",
    "                 data_augmentation: bool = False,\n",
    "                 line_mode: bool = False) -> None:\n",
    "        # dynamic width only supported when no data augmentation happens\n",
    "        assert not (dynamic_width and data_augmentation)\n",
    "        # when padding is on, we need dynamic width enabled\n",
    "        assert not (padding > 0 and not dynamic_width)\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.padding = padding\n",
    "        self.dynamic_width = dynamic_width\n",
    "        self.data_augmentation = data_augmentation\n",
    "        self.line_mode = line_mode\n",
    "\n",
    "    @staticmethod\n",
    "    def _truncate_label(text: str, max_text_len: int) -> str:\n",
    "        \"\"\"\n",
    "        Function ctc_loss can't compute loss if it cannot find a mapping between text label and input\n",
    "        labels. Repeat letters cost double because of the blank symbol needing to be inserted.\n",
    "        If a too-long label is provided, ctc_loss returns an infinite gradient.\n",
    "        \"\"\"\n",
    "        cost = 0\n",
    "        for i in range(len(text)):\n",
    "            if i != 0 and text[i] == text[i - 1]:\n",
    "                cost += 2\n",
    "            else:\n",
    "                cost += 1\n",
    "            if cost > max_text_len:\n",
    "                return text[:i]\n",
    "        return text\n",
    "\n",
    "    def _simulate_text_line(self, batch: Batch) -> Batch:\n",
    "        \"\"\"Create image of a text line by pasting multiple word images into an image.\"\"\"\n",
    "\n",
    "        default_word_sep = 30\n",
    "        default_num_words = 5\n",
    "\n",
    "        # go over all batch elements\n",
    "        res_imgs = []\n",
    "        res_gt_texts = []\n",
    "        for i in range(batch.batch_size):\n",
    "            # number of words to put into current line\n",
    "            num_words = random.randint(1, 8) if self.data_augmentation else default_num_words\n",
    "\n",
    "            # concat ground truth texts\n",
    "            curr_gt = ' '.join([batch.gt_texts[(i + j) % batch.batch_size] for j in range(num_words)])\n",
    "            res_gt_texts.append(curr_gt)\n",
    "\n",
    "            # put selected word images into list, compute target image size\n",
    "            sel_imgs = []\n",
    "            word_seps = [0]\n",
    "            h = 0\n",
    "            w = 0\n",
    "            for j in range(num_words):\n",
    "                curr_sel_img = batch.imgs[(i + j) % batch.batch_size]\n",
    "                curr_word_sep = random.randint(20, 50) if self.data_augmentation else default_word_sep\n",
    "                h = max(h, curr_sel_img.shape[0])\n",
    "                w += curr_sel_img.shape[1]\n",
    "                sel_imgs.append(curr_sel_img)\n",
    "                if j + 1 < num_words:\n",
    "                    w += curr_word_sep\n",
    "                    word_seps.append(curr_word_sep)\n",
    "\n",
    "            # put all selected word images into target image\n",
    "            target = np.ones([h, w], np.uint8) * 255\n",
    "            x = 0\n",
    "            for curr_sel_img, curr_word_sep in zip(sel_imgs, word_seps):\n",
    "                x += curr_word_sep\n",
    "                y = (h - curr_sel_img.shape[0]) // 2\n",
    "                target[y:y + curr_sel_img.shape[0]:, x:x + curr_sel_img.shape[1]] = curr_sel_img\n",
    "                x += curr_sel_img.shape[1]\n",
    "\n",
    "            # put image of line into result\n",
    "            res_imgs.append(target)\n",
    "\n",
    "        return Batch(res_imgs, res_gt_texts, batch.batch_size)\n",
    "\n",
    "    def process_img(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Resize to target size, apply data augmentation.\"\"\"\n",
    "\n",
    "        # there are damaged files in IAM dataset - just use black image instead\n",
    "        if img is None:\n",
    "            img = np.zeros(self.img_size[::-1])\n",
    "\n",
    "        # data augmentation\n",
    "        img = img.astype(np.float)\n",
    "        if self.data_augmentation:\n",
    "            # photometric data augmentation\n",
    "            if random.random() < 0.25:\n",
    "                def rand_odd():\n",
    "                    return random.randint(1, 3) * 2 + 1\n",
    "                img = cv2.GaussianBlur(img, (rand_odd(), rand_odd()), 0)\n",
    "            if random.random() < 0.25:\n",
    "                img = cv2.dilate(img, np.ones((3, 3)))\n",
    "            if random.random() < 0.25:\n",
    "                img = cv2.erode(img, np.ones((3, 3)))\n",
    "\n",
    "            # geometric data augmentation\n",
    "            wt, ht = self.img_size\n",
    "            h, w = img.shape\n",
    "            f = min(wt / w, ht / h)\n",
    "            fx = f * np.random.uniform(0.75, 1.05)\n",
    "            fy = f * np.random.uniform(0.75, 1.05)\n",
    "\n",
    "            # random position around center\n",
    "            txc = (wt - w * fx) / 2\n",
    "            tyc = (ht - h * fy) / 2\n",
    "            freedom_x = max((wt - fx * w) / 2, 0)\n",
    "            freedom_y = max((ht - fy * h) / 2, 0)\n",
    "            tx = txc + np.random.uniform(-freedom_x, freedom_x)\n",
    "            ty = tyc + np.random.uniform(-freedom_y, freedom_y)\n",
    "\n",
    "            # map image into target image\n",
    "            M = np.float32([[fx, 0, tx], [0, fy, ty]])\n",
    "            target = np.ones(self.img_size[::-1]) * 255\n",
    "            img = cv2.warpAffine(img, M, dsize=self.img_size, dst=target, borderMode=cv2.BORDER_TRANSPARENT)\n",
    "\n",
    "            # photometric data augmentation\n",
    "            if random.random() < 0.5:\n",
    "                img = img * (0.25 + random.random() * 0.75)\n",
    "            if random.random() < 0.25:\n",
    "                img = np.clip(img + (np.random.random(img.shape) - 0.5) * random.randint(1, 25), 0, 255)\n",
    "            if random.random() < 0.1:\n",
    "                img = 255 - img\n",
    "\n",
    "        # no data augmentation\n",
    "        else:\n",
    "            if self.dynamic_width:\n",
    "                ht = self.img_size[1]\n",
    "                h, w = img.shape\n",
    "                f = ht / h\n",
    "                wt = int(f * w + self.padding)\n",
    "                wt = wt + (4 - wt) % 4\n",
    "                tx = (wt - w * f) / 2\n",
    "                ty = 0\n",
    "            else:\n",
    "                wt, ht = self.img_size\n",
    "                h, w = img.shape\n",
    "                f = min(wt / w, ht / h)\n",
    "                tx = (wt - w * f) / 2\n",
    "                ty = (ht - h * f) / 2\n",
    "\n",
    "            # map image into target image\n",
    "            M = np.float32([[f, 0, tx], [0, f, ty]])\n",
    "            target = np.ones([ht, wt]) * 255\n",
    "            img = cv2.warpAffine(img, M, dsize=(wt, ht), dst=target, borderMode=cv2.BORDER_TRANSPARENT)\n",
    "\n",
    "        # transpose for TF\n",
    "        img = cv2.transpose(img)\n",
    "\n",
    "        # convert to range [-1, 1]\n",
    "        img = img / 255 - 0.5\n",
    "        return img\n",
    "\n",
    "    def process_batch(self, batch: Batch) -> Batch:\n",
    "        if self.line_mode:\n",
    "            batch = self._simulate_text_line(batch)\n",
    "\n",
    "        res_imgs = [self.process_img(img) for img in batch.imgs]\n",
    "        max_text_len = res_imgs[0].shape[0] // 4\n",
    "        res_gt_texts = [self._truncate_label(gt_text, max_text_len) for gt_text in batch.gt_texts]\n",
    "        return Batch(res_imgs, res_gt_texts, batch.batch_size)\n",
    "\n",
    "\n",
    "def main():\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    img = cv2.imread('../data/test.png', cv2.IMREAD_GRAYSCALE)\n",
    "    img_aug = Preprocessor((256, 32), data_augmentation=True).process_img(img)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(cv2.transpose(img_aug) + 0.5, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
